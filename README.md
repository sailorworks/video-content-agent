# ğŸ¬ Viral AI Influencer Video Content Agent

An AI system that turns your idea into a ready-to-post viral short video. You give a topic, and the system automatically finds trending content across platforms, writes an engaging script (with a chance for you to review and edit it), generates a natural human-like voiceover, and produces a polished short-form videoâ€”all with minimal effort from you.

## ğŸ“º Demo

> End-to-end run: topic â†’ research â†’ script approval â†’ voiceover â†’ final short video

https://github.com/user-attachments/assets/5b541fcd-1e78-47c1-a41a-870aef529acc


## âœ¨ Features

- ğŸ” **Multi-Platform Research**: Automatically discovers trending content from YouTube Shorts, Twitter/X, and fresh news via Exa
- ğŸ“ **AI-Powered Scriptwriting**: Generates viral-optimized scripts using GPT-4o with strict style guidelines
- ğŸ‘¤ **Human Review Loop**: Interactive approval system for script refinement with feedback integration
- ğŸ™ï¸ **Professional Voiceover**: High-quality text-to-speech using ElevenLabs with multilingual support
- ğŸ¥ **Automated Video Production**: Creates polished vertical videos (9:16) using HeyGen avatars
- ğŸ”„ **End-to-End Automation**: Seamless pipeline from topic input to final video delivery

## ğŸ—ï¸ Architecture

The system operates through four sequential stages:

```mermaid
graph LR
    A[Topic Input] --> B[Research Stage]
    B --> C[Scripting Stage]
    C --> D{Human Review}
    D -->|Approved| E[Audio Generation]
    D -->|Feedback| C
    E --> F[Video Generation]
    F --> G[Final Video]
```


## ğŸš€ Getting Started

### Prerequisites

- **Node.js** 18+ and npm
- **Composio Account** ([Sign up here](https://platform.composio.dev))
- **API Keys** for:
  - OpenAI (GPT-4o)
  - ElevenLabs
  - HeyGen
  - Exa
  
### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/video-content-agent.git
   cd video-content-agent
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```
3. **Authenticate services via Composio**
   
   You'll need to connect each service through Composio's authentication flow:
   - Log in to [Composio Dashboard](https://platform.composio.dev)
   - Create a new project.
   - Go to settings for COMPOSIO_API_KEY
   - Navigate to "Auth configs".
   - Connect: YouTube, Twitter, Exa, ElevenLabs, and HeyGen(self explanatory).
   - Take auth config ids from the dashboard and paste it in the .env file.


4. **Set up environment variables**
   
   Create a `.env` file in the root directory:
   ```env
   # OpenAI
   OPENAI_API_KEY=your_openai_api_key
   
   # Composio
   COMPOSIO_API_KEY=your_composio_api_key
   COMPOSIO_USER_ID=your_user_id
   
   # Auth Config IDs (from Composio dashboard)
   YOUTUBE_AUTH_CONFIG_ID=your_youtube_config_id
   TWITTER_AUTH_CONFIG_ID=your_twitter_config_id
   EXA_AUTH_CONFIG_ID=your_exa_config_id
   ELEVENLABS_AUTH_CONFIG_ID=your_elevenlabs_config_id
   HEYGEN_AUTH_CONFIG_ID=your_heygen_config_id
   ```



5. **Build the project**
   ```bash
   npm run build
   ```

### Usage

Run the agent:
```bash
npm start
```

You'll be prompted to enter a topic:
```
? What topic would you like to generate video content for? â€º voice agents in 2025
```

The agent will then:
1. Research the topic across platforms (~30-60 seconds)
2. Generate a script and request your approval
3. Generate audio from the approved script (~10-20 seconds)
4. Create the final video (~2-5 minutes depending on HeyGen queue)

5. ## ğŸ’» CLI Usage

The CLI provides a command-line interface for generating viral video content.

### Installation

```bash
npm install -g video-content-agent
```

### Quick Start

```bash
video-content-agent --topic "Your topic here"
```

### Options

- `--topic <topic>`: The topic for video content generation (required)
- `--output <path>`: Output directory for the generated video (default: ./output)
- `--skip-approval`: Skip the interactive script approval step
- `--dry-run`: Test the pipeline without generating the actual video

### Examples

#### Generate a video with approval:
```bash
video-content-agent --topic "AI trends in 2024"
```

#### Generate a video and save to custom location:
```bash
video-content-agent --topic "Web development" --output ./my-videos
```

#### Skip approval step:
```bash
video-content-agent --topic "Gaming news" --skip-approval
```


## ğŸ“ Project Structure

```
video-content-agent/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ research.ts          # Multi-platform content discovery
â”‚   â”‚   â”œâ”€â”€ scripting.ts         # AI script generation
â”‚   â”‚   â”œâ”€â”€ human_review.ts      # Interactive approval system
â”‚   â”‚   â”œâ”€â”€ audio.ts             # ElevenLabs voice synthesis
â”‚   â”‚   â””â”€â”€ video_generation.ts  # HeyGen video production
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ client.ts            # Composio toolkit sessions
â”‚   â””â”€â”€ state/
â”‚       â””â”€â”€ state.ts             # TypeScript type definitions
â”œâ”€â”€ index.ts                      # Main pipeline orchestrator
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â””â”€â”€ .env                          # Environment variables (not committed)
```



## ğŸ”§ Configuration

### Customizing Voice Settings

Edit `src/agents/audio.ts`:
```typescript
// Change voice ID (find IDs in ElevenLabs dashboard)
const VOICE_ID = "EIsgvJT3rwoPvRFG6c4n"; // Default: Clara

// Change model
const MODEL_ID = "eleven_multilingual_v2";
```

### Customizing Avatar

Edit `src/agents/video_generation.ts`:
```typescript
// Change avatar ID (find IDs in HeyGen dashboard)
const AVATAR_ID = "109cdee34a164003b0e847ffce93828e"; // Default: Jasmine

// Change video dimensions
const dimension = { width: 720, height: 1280 }; // 9:16 vertical
```

### Script Style Guidelines

Modify `src/agents/scripting.ts` to adjust:
- Script length (default: 75-85 words)
- Tone and reading level
- Banned words/phrases
- Structural requirements

## ğŸ› Troubleshooting

### Authentication Errors

If you see authentication links in the output:
```
ğŸš¨ AUTHENTICATION REQUIRED: Please click here to authenticate...
```
1. Click the provided link
2. Complete the OAuth flow
3. Restart the agent with `npm start`


### Script Quality Issues

- Provide detailed feedback during human review
- Adjust style guidelines in `scripting.ts`
- Ensure research data is comprehensive (check API quotas)

## ğŸ“ Development

### Running in Development Mode

Use `tsx` for faster iteration without building:
```bash
npx tsx index.ts
```

### Adding New Research Sources

1. Create a new toolkit session in `research.ts`
2. Define an agent with specific instructions
3. Parse and integrate results into `ResearchData`

### Extending the Pipeline

Add new stages by:
1. Creating a new agent file in `src/agents/`
2. Importing and calling it in `index.ts`
3. Updating `AgentState` type in `src/state/state.ts`


## ğŸ’» CLI Interface

An interactive command-line interface (CLI) for the video-content-agent is now available! Built with **Ink + React**, the CLI provides a user-friendly terminal-based workflow.

### Installation

```bash
npm install
```

### Running the CLI

**Development Mode:**
```bash
npm run dev
```

**Production Mode:**
```bash
npm run build
npm start
```

### Features

- ğŸ¯ **Interactive Input** - Beautiful terminal forms for topic input
- â³ **Progress Indicators** - Real-time spinners during processing
- ğŸ“ **Script Review** - Formatted script display with feedback collection
- ğŸ”„ **Full Workflow** - Complete pipeline from research to video production
- âš ï¸ **Error Handling** - Graceful error messages and recovery
- ğŸ§ª **Mock Implementations** - Test without real API calls

### Workflow States

1. **Input** - Enter your video topic
2. **Research** - Agent researches trending content
3. **Generate** - AI generates optimized script
4. **Review** - Review script and provide feedback
5. **Voiceover** - Generate voiceover using ElevenLabs
6. **Video** - Produce final polished video
7. **Done** - Completion!

### Architecture

- **Framework**: Ink (React renderer for CLIs)
- **Language**: TypeScript
- **UI Components**: @inkjs/ui
- **Styling**: Chalk
- **State Management**: React Hooks

### Project Structure

```
src/cli/
â”œâ”€â”€ app.tsx              # Main Ink app with workflow orchestration
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ FormInput.tsx    # Interactive input forms
â”‚   â”œâ”€â”€ ProgressSpinner.tsx  # Loading indicators
â”‚   â”œâ”€â”€ ScriptReview.tsx # Script display and feedback
â”‚   â””â”€â”€ StyledText.tsx   # Formatted text output
â””â”€â”€ workflow.ts          # Workflow logic with mock functions
```

### Related

- PR #5: Initial CLI implementation using Ink + React
- Issue #4: Feature proposal for interactive CLI
## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments


- [Composio](https://composio.dev) for seamless API integrations and SDK.
- [OpenAI](https://openai.com) for GPT-4o and the Agents SDK
- [ElevenLabs](https://elevenlabs.io) for high-quality voice synthesis
- [HeyGen](https://heygen.com) for AI avatar technology

---
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Built with â¤ï¸ using [Composio](https://github.com/ComposioHQ/composio)**
